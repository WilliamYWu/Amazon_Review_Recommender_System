{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "175e7786-8e51-4e84-849b-9d00e5d4c92a",
   "metadata": {},
   "source": [
    "# Recommender System with Deep Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "951e16ec",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "983b6c02",
   "metadata": {},
   "source": [
    "### Packages & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc723e1-d85f-40b3-91fa-0e8f85395711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import typing\n",
    "\n",
    "import urllib.request\n",
    "import multiprocessing as mp\n",
    "import concurrent.futures\n",
    "\n",
    "import gzip\n",
    "import unicodedata\n",
    "import math\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9021e6d4",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83509cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = os.path.join(\"D:\" + os.sep, \"Code\", \"PYTHON\", \"Amazon_Recommender_System\")\n",
    "\n",
    "CODE_DIR = os.path.join(MAIN_DIR, \"Code\")\n",
    "\n",
    "ANALYSIS_DIR = os.path.join(MAIN_DIR, \"Analysis\")\n",
    "DATA_DIR = os.path.join(MAIN_DIR, \"Data\")\n",
    "\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR, \"Raw\")\n",
    "CLEAN_DATA_DIR = os.path.join(DATA_DIR, \"Clean\")\n",
    "\n",
    "BOOKS_RAW_DIR = os.path.join(RAW_DATA_DIR, \"Books\")\n",
    "BOOKS_CLEAN_DIR = os.path.join(CLEAN_DATA_DIR, \"Books\")\n",
    "BOOKS_SENTIMENT_DIR = os.path.join(BOOKS_CLEAN_DIR, \"Sentiment\")\n",
    "\n",
    "CHUNK_SIZE = 1000000\n",
    "\n",
    "NUM_CORES = math.ceil(mp.cpu_count()/2)\n",
    "\n",
    "RANDOM_STATE = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71a50b4e",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7a6c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(dir_list: list) -> None:\n",
    "    for directory in dir_list:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "def is_directory_empty(dir_path: str) -> bool:\n",
    "    return len(os.listdir(dir_path)) == 0\n",
    "\n",
    "def set_random_seed(state=1):\n",
    "    gens = (np.random.seed, torch.manual_seed, torch.cuda.manual_seed)\n",
    "    for set_state in gens:\n",
    "        set_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3231a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directory([CODE_DIR, \n",
    "                  ANALYSIS_DIR,\n",
    "                  DATA_DIR, \n",
    "                  RAW_DATA_DIR, \n",
    "                  CLEAN_DATA_DIR,\n",
    "                  BOOKS_RAW_DIR,\n",
    "                  BOOKS_CLEAN_DIR,\n",
    "                  BOOKS_SENTIMENT_DIR,\n",
    "                  ])\n",
    "\n",
    "set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e53f8033",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aca015dd",
   "metadata": {},
   "source": [
    "### Loading Data In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc72a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More memory efficient version. Takes longer but is far more consistent than the previous version. \n",
    "def process_data(url: str, \n",
    "                 chunk_size: int, \n",
    "                 num_workers: int,\n",
    "                 output_dir: str) -> None:\n",
    "    \n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with gzip.open(response, \"rt\") as gz_file:\n",
    "            chunk = []\n",
    "            chunk_count = 0\n",
    "\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "                for line in gz_file:\n",
    "                    chunk.append(line)\n",
    "\n",
    "                    if len(chunk) == chunk_size:\n",
    "                        executor.submit(process_chunk, list(chunk), os.path.join(output_dir, f\"chunk_{chunk_count}.json\"))\n",
    "                        chunk = []\n",
    "                        chunk_count += 1\n",
    "\n",
    "                # Process the remaining lines in the last chunk\n",
    "                if chunk:\n",
    "                    executor.submit(process_chunk, list(chunk), os.path.join(output_dir, f\"chunk_{chunk_count}.json\"))\n",
    "\n",
    "def process_chunk(chunk: list,\n",
    "                  filename: str) -> None:\n",
    "    \n",
    "    with open(filename, 'w') as file:\n",
    "        file.writelines(chunk)\n",
    "    print(f\"Processed chunk: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c2af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "----- PROCESS_DATA -----\n",
    "GAME URL \"https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Video_Games_5.json.gz\"\n",
    "BOOK URL \"https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Books_5.json.gz\"\n",
    "\n",
    "EXPERIMENTS FOR 27 MILLION\n",
    "----- THREAD CSV_FILE -----\n",
    "1. 100000 chunk -> 22min 26sec\n",
    "\n",
    "----- THREAD JSON_FILE RUNTIMES-----\n",
    "1. 100000 chunk -> 20min 55sec\n",
    "2. 100000 chunk -> 49min 1sec -> No idea why this happened on a fresh start\n",
    "3. 500000 chunk -> 18min 45sec\n",
    "4. 1000000 chunk -> 17min 5sec\n",
    "\n",
    "NEW STABLE IMPLEMENTATION\n",
    "1. 1000000 chunk -> 22min 22sec\n",
    "'''\n",
    "url = \"https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Books_5.json.gz\"\n",
    "process_data(url, CHUNK_SIZE, NUM_CORES, BOOKS_RAW_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe328f04",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f706d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_value(dictionary: dict):\n",
    "    return dictionary.get(\"Format:\") if isinstance(dictionary, dict) else None\n",
    "\n",
    "def filter_comment_length(reviews: pd.DataFrame, \n",
    "                          minimum: int) -> pd.DataFrame:\n",
    "    reviews = reviews.copy()\n",
    "    reviews[\"review_len\"] = reviews[\"review_text\"].str.split().str.len()\n",
    "    reviews = reviews.loc[(reviews[\"review_len\"] > minimum)]\n",
    "    return reviews\n",
    "\n",
    "def remove_symbols(reviews: pd.Series) -> pd.Series:\n",
    "    return reviews.apply(lambda x: re.sub(r\"\\s+|[^a-zA-Z0-9\\s]\", \"\", x)) # Cleans up duplicate space and special characters.\n",
    "\n",
    "def remove_irrelevant_info(reviews: pd.Series) -> pd.Series:\n",
    "    return reviews.apply(lambda x: re.sub(r\"http\\S+|www.\\S+|#\\S+|<.*?>|\\(|\\)|\\d+\", \"\", x)) # Cleans up URL, hashtags, parenthesis, and numbers.\n",
    "\n",
    "def reduce_characters(reviews: pd.Series) -> pd.Series:\n",
    "    return reviews.apply(lambda x: re.sub(r\"[^\\w\\s]|(.)\\1+\", \"\", x)) # Remove excessive punctuation and repeated characters\n",
    "\n",
    "def normalize_encoding(reviews: pd.Series) -> pd.Series:\n",
    "    return reviews.apply(lambda x: unicodedata.normalize(\"NFKD\", x).encode(\"ASCII\", \"ignore\").decode(\"utf-8\")) # Encodes and Decodes the data so that we have consistency in text\n",
    "        \n",
    "def clean_chunk(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        \"overall\": \"rating\",\n",
    "        \"reviewTime\": \"review_date\",\n",
    "        \"reviewerID\": \"reviewer_id\",\n",
    "        \"asin\": \"product_id\",\n",
    "        \"reviewText\": \"review_text\",\n",
    "    })\n",
    "\n",
    "    df[\"vote\"] = df[\"vote\"].fillna(0)\n",
    "    df[\"vote\"] = pd.to_numeric(df[\"vote\"].astype(\"str\").str.replace(\",\",\"\")).astype(\"int32\")\n",
    "    df = df[df[\"vote\"] >= 5]\n",
    "    df = filter_comment_length(df, 30)\n",
    "    df.drop([\"unixReviewTime\", \"image\", \"summary\", \"reviewerName\"], axis=1, inplace=True)\n",
    "    \n",
    "    df[\"review_date\"] = pd.to_datetime(df[\"review_date\"], format=\"%m %d, %Y\")\n",
    "    df[\"style\"] = df[\"style\"].apply(extract_value)\n",
    "\n",
    "    df[\"review_text\"] = df[\"review_text\"].str.lower()\n",
    "    df[\"review_text\"] = remove_irrelevant_info(df[\"review_text\"])\n",
    "    df[\"review_text\"] = reduce_characters(df[\"review_text\"])\n",
    "    df[\"review_text\"] = normalize_encoding(df[\"review_text\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcaa284",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file_names = [f\"chunk_{file_num}.json\" for file_num in range(len(os.listdir(BOOKS_RAW_DIR)))]\n",
    "\n",
    "for raw_file_name in raw_file_names:\n",
    "    raw_df_list = []\n",
    "    raw_df = pd.read_json(os.path.join(BOOKS_RAW_DIR, raw_file_name), lines=True)\n",
    "   \n",
    "    raw_df = clean_chunk(raw_df)\n",
    "    print(f\"{raw_file_name} DIMENSIONS: {raw_df.shape}\")\n",
    "    clean_dir = os.path.join(BOOKS_CLEAN_DIR, raw_file_name)\n",
    "    raw_df.to_json(clean_dir, orient=\"records\")\n",
    "\n",
    "    del raw_df\n",
    "    gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3eae861a-afe7-4a17-97a4-a1dea5fc2ee9",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b721b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_text(column: pd.Series, \n",
    "               batch_size: int) -> list:\n",
    "    \n",
    "    batches = np.array_split(np.array(column.values), int(np.ceil(len(column)/ batch_size)))\n",
    "    batches = [batch.tolist() for batch in batches]\n",
    "    return batches\n",
    "\n",
    "def load_sentiment_model(model: str):\n",
    "\n",
    "    return TextClassifier.load(model)\n",
    "\n",
    "def is_float(value):\n",
    "      \n",
    "      try:\n",
    "        float(value)\n",
    "        return True\n",
    "      except ValueError:\n",
    "        return False\n",
    "\n",
    "def analyze_sentiment(model, \n",
    "                      batch: np.ndarray):\n",
    "    \n",
    "    score = []\n",
    "    for sentence in batch:\n",
    "        sentence = Sentence(sentence)\n",
    "        model.predict(sentence, verbose=False)\n",
    "        try:\n",
    "            process = re.sub(r\"\\(|\\)\",\"\",str(sentence.labels[0]))\n",
    "            number = [float(s) for s in  process.split() if is_float(s) is True]\n",
    "            if \"POSITIVE\" in process:\n",
    "                score.append(number[0])\n",
    "            elif \"NEGATIVE\" in process:\n",
    "                score.append(-number[0])\n",
    "        except IndexError:\n",
    "            print(sentence)\n",
    "            score.append(np.nan)\n",
    "    return score\n",
    "   \n",
    "def process_batches(models: list[str], \n",
    "                    batches: list):\n",
    "                    \n",
    "    models_loaded = [load_sentiment_model(model) for model in models]\n",
    "    print(\"[Starting process...]\")\n",
    "    sentiment_results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers= NUM_CORES) as executor:\n",
    "        sentiment_tasks = [executor.submit(analyze_sentiment, model, batch) for model, batch in zip(models_loaded, batches)]\n",
    "        for completed_task in concurrent.futures.as_completed(sentiment_tasks):\n",
    "            result = completed_task.result()\n",
    "            sentiment_results.extend(result)\n",
    "            print(\"[Finished with a Batch]\")\n",
    "        return sentiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09444c36-567e-41fc-9bf6-4e82688ae8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_file_names = [f\"chunk_{file_num}.json\" for file_num in range(len(os.listdir(BOOKS_CLEAN_DIR)))]\n",
    "\n",
    "for clean_file_name in clean_file_names[4:5]:\n",
    "    clean_df = pd.read_json(os.path.join(BOOKS_CLEAN_DIR, clean_file_name), orient=\"columns\")\n",
    "    batch_size = math.ceil(len(clean_df)/NUM_CORES) \n",
    "       \n",
    "    batches = batch_text(clean_df[\"review_text\"], batch_size)\n",
    "    clean_df[\"sentiment_score\"] = process_batches([\"en-sentiment\"] * len(batches), batches)\n",
    "    sentiment_dir = os.path.join(BOOKS_SENTIMENT_DIR, clean_file_name)\n",
    "    clean_df.to_json(sentiment_dir, orient=\"records\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b39d037",
   "metadata": {},
   "source": [
    "## Neural Network Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b0c4a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>verified</th>\n",
       "      <th>review_date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>style</th>\n",
       "      <th>vote</th>\n",
       "      <th>review_len</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>1087776000000</td>\n",
       "      <td>A2NJO6YE954DBH</td>\n",
       "      <td>0001712799</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>6</td>\n",
       "      <td>298</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>982972800000</td>\n",
       "      <td>A1K1JW1C5CUSUZ</td>\n",
       "      <td>0001712799</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>23</td>\n",
       "      <td>431</td>\n",
       "      <td>0.9937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1089244800000</td>\n",
       "      <td>A1JS302JFHH9DJ</td>\n",
       "      <td>0002006448</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9</td>\n",
       "      <td>273</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>1079049600000</td>\n",
       "      <td>A26QTCZG2XR3JH</td>\n",
       "      <td>0002006448</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>15</td>\n",
       "      <td>277</td>\n",
       "      <td>-0.6053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>1071360000000</td>\n",
       "      <td>A36X9BU9JB8KCE</td>\n",
       "      <td>0002006448</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>5</td>\n",
       "      <td>495</td>\n",
       "      <td>0.9994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  verified    review_date     reviewer_id  product_id       style   \n",
       "0       4     False  1087776000000  A2NJO6YE954DBH  0001712799   Hardcover  \\\n",
       "1       5     False   982972800000  A1K1JW1C5CUSUZ  0001712799   Hardcover   \n",
       "2       3     False  1089244800000  A1JS302JFHH9DJ  0002006448   Hardcover   \n",
       "3       5      True  1079049600000  A26QTCZG2XR3JH  0002006448   Hardcover   \n",
       "4       5     False  1071360000000  A36X9BU9JB8KCE  0002006448   Hardcover   \n",
       "\n",
       "   vote  review_len  sentiment_score  \n",
       "0     6         298           0.9999  \n",
       "1    23         431           0.9937  \n",
       "2     9         273           0.9999  \n",
       "3    15         277          -0.6053  \n",
       "4     5         495           0.9994  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.DataFrame()\n",
    "for filename in os.listdir(BOOKS_SENTIMENT_DIR):\n",
    "    sentiment_df = pd.read_json(os.path.join(BOOKS_SENTIMENT_DIR, filename), orient=\"columns\")\n",
    "    sentiment_df.drop(columns=[\"review_text\"], inplace=True)\n",
    "    merged_df = pd.concat([merged_df, sentiment_df])\n",
    "    \n",
    "merged_df.reset_index(drop=True, inplace=True)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02212d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range -1.0 to -0.5: 198373\n",
      "Range -0.5 to 0.0: 4\n",
      "Range 0.0 to 0.5: 0\n",
      "Range 0.5 to 1.0: 192154\n"
     ]
    }
   ],
   "source": [
    "ranges = [(-1.0000, -0.5000), (-0.5000, 0.0000), (0.0000, 0.5000), (0.5000, 1.0000)] # Define the ranges\n",
    "\n",
    "counts = {f\"{r[0]} to {r[1]}\": 0 for r in ranges} # Initialize a dictionary to store the counts\n",
    "\n",
    "# Count the values within each range\n",
    "for value in merged_df[\"sentiment_score\"]:\n",
    "    for r in ranges:\n",
    "        if r[0] <= value < r[1]:\n",
    "            counts[f\"{r[0]} to {r[1]}\"] += 1\n",
    "\n",
    "for r, count in counts.items():\n",
    "    print(f\"Range {r}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a748ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_transformation(data: np.ndarray, \n",
    "                            type: typing.Literal[\"uniform\",\"normal\"]) -> np.ndarray:\n",
    "    \n",
    "    qt = QuantileTransformer(output_distribution=type)\n",
    "    return  qt.fit_transform(data)\n",
    "\n",
    "def create_dataset(df:pd.DataFrame, ratings_column: str):\n",
    "    unique_users = df[\"reviewer_id\"].unique()\n",
    "    user_to_index = {old: new for new, old in enumerate(unique_users)}\n",
    "    new_users = df[\"reviewer_id\"].map(user_to_index)\n",
    "\n",
    "    unique_items = df[\"product_id\"].unique()\n",
    "    item_to_index = {old: new for new, old in enumerate(unique_items)}\n",
    "    new_items = df[\"product_id\"].map(item_to_index)\n",
    "\n",
    "    n_users = unique_users.shape[0]\n",
    "    n_items = unique_items.shape[0]\n",
    "    \n",
    "    X = pd.DataFrame({\"user_id\": new_users, \"item_id\": new_items})\n",
    "    y = df[ratings_column].astype(np.float32)\n",
    "    return (n_users, n_items), (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "334c3d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: 165643 users, 50565 items\n",
      "Dataset shape: (389012, 2)\n",
      "Target shape: (389012,)\n"
     ]
    }
   ],
   "source": [
    "merged_df.dropna(inplace=True)\n",
    "sentiment_score = np.array(merged_df[\"sentiment_score\"]).reshape(-1,1) # Needs to be 2D to use with QuantileTransformer\n",
    "merged_df[\"sentiment_uq\"] = quantile_transformation(sentiment_score, \"uniform\") # Reshape into uniform distribution -> Everything will be equally weighted\n",
    "merged_df[\"sentiment_nq\"] = quantile_transformation(sentiment_score, \"normal\") # reshape into normal distribution -> will create bias towards average values -0.5 to 0.5\n",
    "\n",
    "(n_users, n_items), (X, y) = create_dataset(merged_df, \"sentiment_score\")\n",
    "print(f\"Embeddings: {n_users} users, {n_items} items\")\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fddf75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "        def __init__(self,\n",
    "                     n_users,\n",
    "                     n_items,\n",
    "                     n_factors,\n",
    "                     sparse=False):\n",
    "                \n",
    "                super(MatrixFactorization, self).__init__()\n",
    "                self.n_users = n_users\n",
    "                self.n_items = n_items\n",
    "                self.n_factors = n_factors\n",
    "\n",
    "                self.user_biases = nn.Embedding(n_users, 1, sparse=sparse)\n",
    "                self.item_biases = nn.Embedding(n_items, 1, sparse=sparse)\n",
    "                self.user_embeddings = nn.Embedding(n_users, n_factors, sparse=sparse)\n",
    "                self.item_embeddings = nn.Embedding(n_items, n_factors, sparse=sparse)\n",
    "\n",
    "                self.sparse = sparse\n",
    "\n",
    "        def forward(self, users, items):\n",
    "                user_embedding = self.user_embeddings(users)\n",
    "                item_embedding = self.item_embeddings(items)\n",
    "                predictions = torch.squeeze(self.user_biases(users)) + torch.squeeze(self.item_biases(items))\n",
    "                predictions += torch.sum(user_embedding * item_embedding, dim=1)\n",
    "                return predictions.flatten()\n",
    "        \n",
    "        def __call__(self, *args):\n",
    "                return self.forward(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1551cf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Test Loss: 34.506852623271314\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m     predictions \u001b[39m=\u001b[39m model(users, items)\n\u001b[0;32m     30\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(predictions, ratings)\n\u001b[1;32m---> 31\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     32\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     33\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\Willi Wu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Willi Wu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, y = np.asarray(X), np.asarray(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 22)\n",
    "\n",
    "train_dataset = TensorDataset(torch.LongTensor(X_train), torch.FloatTensor(y_train))\n",
    "test_dataset = TensorDataset(torch.LongTensor(X_test), torch.FloatTensor(y_test))\n",
    "\n",
    "# Define the batch size for training\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=32)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)\n",
    "\n",
    "def load_processing(batch, ratings):\n",
    "    users_items = batch\n",
    "    users = users_items[:, 0]\n",
    "    items = users_items[:, 1]\n",
    "    return users, items, ratings\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch, ratings in train_loader:\n",
    "        users, items, ratings = load_processing(batch, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, items)\n",
    "        loss = loss_fn(predictions, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        total_loss = 0.0\n",
    "        for batch, ratings in test_loader:\n",
    "            users, items, ratings = load_processing(batch, ratings)\n",
    "            predictions = model(users, items)\n",
    "            total_loss += loss_fn(predictions, ratings).item()\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader) # Print the loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Test Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed-Forward Network as defined in Zhou Xu 2016\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_users,\n",
    "                 n_items,\n",
    "                 n_factors=64,\n",
    "                 hidden_dim,\n",
    "                 dropout_p=20,\n",
    "                 sparse=False,\n",
    "                 output_dim):\n",
    "        \n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.n_factors = n_factors\n",
    "\n",
    "        self.user_biases = nn.Embedding(n_users, 1, sparse=sparse)\n",
    "        self.item_biases = nn.Embedding(n_items, 1, sparse=sparse)\n",
    "        self.user_embeddings = nn.Embedding(n_users, n_factors, sparse=sparse)\n",
    "        self.item_embeddings = nn.Embedding(n_items, n_factors, sparse=sparse)\n",
    "\n",
    "        self.dropout_p = dropout_p\n",
    "        self.dropout = nn.Dropout(p=self.dropout_p)\n",
    "        \n",
    "        self.sparse=sparse\n",
    "\n",
    "        # Define the layers\n",
    "        self.linear1 = nn.Linear(n_factors*2, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        self.linear3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        self.linear4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout4 = nn.Dropout(0.2)\n",
    "        self.bn4 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        self.linear5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout5 = nn.Dropout(0.2)\n",
    "        self.bn5 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        self.linear6 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        users_embedding = self.user_embeddings(users)\n",
    "        items_embedding = self.item_embeddings(items)\n",
    "\t\n",
    "        x = torch.cat([users_embedding, items_embedding], 1) # concatenate user and item embeddings to form input\n",
    "       \n",
    "        h1 = self.bn1(self.dropout1(F.relu(self.linear1(x))))  # Layer 1: ReLU(W(1)x + b1)\n",
    "\n",
    "        h2 = self.bn2(self.dropout2(torch.tanh(self.linear2(h1)))) # Layer 2: tanh(W(2)h(1) + b2)\n",
    "\n",
    "        h3 = self.bn3(self.dropout3(F.relu(self.linear3(h2)))) # Layer 3: ReLU(W(3)h(2) + b3)\n",
    "\n",
    "        h4 = self.bn4(self.dropout4(torch.sigmoid(self.linear4(h3)))) # Layer 4: Sigmoid(W(4)h(3) + b4)\n",
    "\n",
    "        h5 = self.bn5(self.dropout5(F.relu(self.linear5(h4)))) # Layer 5: ReLU(W(5)h(4) + b5)\n",
    "\n",
    "        output = F.softmax(self.linear6(h5), dim=1) # Output layer: softmax(Uh(5) + b6)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd60b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM as defined in Zhou Xu 2016\n",
    "class LSTM_Rating(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 n_users, \n",
    "                 n_items, \n",
    "                 n_factors = 64, \n",
    "                 n_output, \n",
    "                 sparse):\n",
    "        \n",
    "        super(LSTM_Rating, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.n_factors = n_factors\n",
    "\n",
    "        self.user_biases = nn.Embedding(n_users, 1, sparse=sparse)\n",
    "        self.item_biases = nn.Embedding(n_items, 1, sparse=sparse)\n",
    "        self.user_embeddings = nn.Embedding(n_users, n_factors, sparse=sparse)\n",
    "        self.item_embeddings = nn.Embedding(n_items, n_factors, sparse=sparse)\n",
    "\n",
    "        self.sparse = sparse\n",
    "        # Input gate\n",
    "        self.Wu = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.Iu = nn.Linear(input_size, hidden_dim)\n",
    "\n",
    "        # Forget gate\n",
    "        self.Wf = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.If = nn.Linear(input_size, hidden_dim)\n",
    "\n",
    "        # Output gate\n",
    "        self.Wo = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.Io = nn.Linear(input_size, hidden_dim)\n",
    "\n",
    "        # New memory cell\n",
    "        self.Wc = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.Ic = nn.Linear(input_size, hidden_dim)\n",
    "\n",
    "    def forward(self, xt, ht_1, ct_1):\n",
    "    \n",
    "        gu = torch.sigmoid(self.Wu(ht_1) + self.Iu(xt)) # Input gate\n",
    "\n",
    "        gf = torch.sigmoid(self.Wf(ht_1) + self.If(xt)) # Forget gate\n",
    "\n",
    "        go = torch.sigmoid(self.Wo(ht_1) + self.Io(xt)) # Output gate\n",
    "\n",
    "        gc = torch.tanh(self.Wc(ht_1) + self.Ic(xt)) # New memory cell\n",
    "\n",
    "        ct = gf * ct_1 + gu * gc  # Final memory cell\n",
    "\n",
    "        ht = torch.tanh(go * ct) # Final hidden state\n",
    "\n",
    "        return ht, ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b3c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    U, S, Vh = torch.linalg.svd(A, full_matrices=False)\n",
    "    x = torch.dist(A, U @ torch.diag(S) @ Vh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e327a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
